"""
GAIM Lab v3.0 Performance Benchmarking
API ì‘ë‹µ ì‹œê°„, ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ì¸¡ì •
"""

import time
import json
import subprocess
import statistics
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import urllib.request
import urllib.error

# ì„¤ì •
BACKEND_URL = "http://localhost:8000"
FRONTEND_URL = "http://localhost:5173"
DEMO_VIDEO = Path(r"D:\AI\GAIM_Lab\video\youtube_demo.mp4")
OUTPUT_DIR = Path(r"D:\Ginue_AI\output\benchmark")


def measure_time(func):
    """ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        elapsed = time.perf_counter() - start
        return result, elapsed
    return wrapper


class PerformanceBenchmark:
    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "system": "GAIM Lab v3.0",
            "benchmarks": {}
        }
    
    def benchmark_api_health(self, iterations: int = 10) -> dict:
        """API í—¬ìŠ¤ì²´í¬ ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ“Š [1/6] API í—¬ìŠ¤ì²´í¬ ë²¤ì¹˜ë§ˆí¬...")
        
        times = []
        success = 0
        
        for i in range(iterations):
            try:
                start = time.perf_counter()
                req = urllib.request.Request(f"{BACKEND_URL}/health")
                with urllib.request.urlopen(req, timeout=5) as response:
                    response.read()
                elapsed = (time.perf_counter() - start) * 1000  # ms
                times.append(elapsed)
                success += 1
            except Exception as e:
                print(f"   âš ï¸ ìš”ì²­ {i+1} ì‹¤íŒ¨: {e}")
        
        result = {
            "endpoint": "/health",
            "iterations": iterations,
            "success_rate": f"{success/iterations*100:.1f}%",
            "avg_response_ms": round(statistics.mean(times), 2) if times else 0,
            "min_response_ms": round(min(times), 2) if times else 0,
            "max_response_ms": round(max(times), 2) if times else 0,
            "std_dev_ms": round(statistics.stdev(times), 2) if len(times) > 1 else 0
        }
        
        print(f"   âœ… í‰ê·  ì‘ë‹µì‹œê°„: {result['avg_response_ms']}ms")
        return result
    
    def benchmark_api_docs(self, iterations: int = 5) -> dict:
        """API ë¬¸ì„œ í˜ì´ì§€ ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ“Š [2/6] API ë¬¸ì„œ (Swagger) ë²¤ì¹˜ë§ˆí¬...")
        
        times = []
        success = 0
        
        for i in range(iterations):
            try:
                start = time.perf_counter()
                req = urllib.request.Request(f"{BACKEND_URL}/docs")
                with urllib.request.urlopen(req, timeout=10) as response:
                    response.read()
                elapsed = (time.perf_counter() - start) * 1000
                times.append(elapsed)
                success += 1
            except Exception as e:
                print(f"   âš ï¸ ìš”ì²­ {i+1} ì‹¤íŒ¨: {e}")
        
        result = {
            "endpoint": "/docs",
            "iterations": iterations,
            "success_rate": f"{success/iterations*100:.1f}%",
            "avg_response_ms": round(statistics.mean(times), 2) if times else 0,
            "min_response_ms": round(min(times), 2) if times else 0,
            "max_response_ms": round(max(times), 2) if times else 0
        }
        
        print(f"   âœ… í‰ê·  ì‘ë‹µì‹œê°„: {result['avg_response_ms']}ms")
        return result
    
    def benchmark_frontend(self, iterations: int = 5) -> dict:
        """í”„ë¡ íŠ¸ì—”ë“œ í˜ì´ì§€ ë¡œë”© ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ“Š [3/6] í”„ë¡ íŠ¸ì—”ë“œ í˜ì´ì§€ ë²¤ì¹˜ë§ˆí¬...")
        
        pages = ["/", "/upload", "/analysis", "/coach", "/portfolio"]
        results = {}
        
        for page in pages:
            times = []
            success = 0
            
            for i in range(iterations):
                try:
                    start = time.perf_counter()
                    req = urllib.request.Request(f"{FRONTEND_URL}{page}")
                    with urllib.request.urlopen(req, timeout=10) as response:
                        response.read()
                    elapsed = (time.perf_counter() - start) * 1000
                    times.append(elapsed)
                    success += 1
                except Exception as e:
                    pass
            
            results[page] = {
                "avg_ms": round(statistics.mean(times), 2) if times else 0,
                "success_rate": f"{success/iterations*100:.0f}%"
            }
        
        avg_all = statistics.mean([r['avg_ms'] for r in results.values() if r['avg_ms'] > 0])
        print(f"   âœ… í‰ê·  í˜ì´ì§€ ë¡œë”©: {avg_all:.1f}ms")
        
        return {
            "pages": results,
            "avg_page_load_ms": round(avg_all, 2)
        }
    
    def benchmark_concurrent_requests(self, concurrent: int = 10) -> dict:
        """ë™ì‹œ ìš”ì²­ ë²¤ì¹˜ë§ˆí¬"""
        print(f"\nğŸ“Š [4/6] ë™ì‹œ ìš”ì²­ ë²¤ì¹˜ë§ˆí¬ ({concurrent}ê°œ)...")
        
        def make_request(i):
            try:
                start = time.perf_counter()
                req = urllib.request.Request(f"{BACKEND_URL}/health")
                with urllib.request.urlopen(req, timeout=10) as response:
                    response.read()
                return (time.perf_counter() - start) * 1000, True
            except:
                return 0, False
        
        start_total = time.perf_counter()
        
        with ThreadPoolExecutor(max_workers=concurrent) as executor:
            results_list = list(executor.map(make_request, range(concurrent)))
        
        total_time = (time.perf_counter() - start_total) * 1000
        
        times = [r[0] for r in results_list if r[1]]
        success = sum(1 for r in results_list if r[1])
        
        result = {
            "concurrent_requests": concurrent,
            "success_count": success,
            "total_time_ms": round(total_time, 2),
            "avg_response_ms": round(statistics.mean(times), 2) if times else 0,
            "throughput_rps": round(success / (total_time / 1000), 2) if total_time > 0 else 0
        }
        
        print(f"   âœ… ì²˜ë¦¬ëŸ‰: {result['throughput_rps']} req/s")
        return result
    
    def benchmark_ffmpeg_extraction(self) -> dict:
        """FFmpeg í”„ë ˆì„/ì˜¤ë””ì˜¤ ì¶”ì¶œ ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ“Š [5/6] FFmpeg ì¶”ì¶œ ë²¤ì¹˜ë§ˆí¬...")
        
        if not DEMO_VIDEO.exists():
            print("   âš ï¸ ë°ëª¨ ì˜ìƒ ì—†ìŒ")
            return {"error": "Demo video not found"}
        
        temp_dir = OUTPUT_DIR / "temp_bench"
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        # í”„ë ˆì„ ì¶”ì¶œ (10ì´ˆ ë¶„ëŸ‰ë§Œ)
        frame_cmd = [
            "ffmpeg", "-y", "-ss", "0", "-t", "10",
            "-i", str(DEMO_VIDEO),
            "-vf", "fps=1,scale=320:-1",
            str(temp_dir / "frame_%03d.jpg"),
            "-loglevel", "error"
        ]
        
        start = time.perf_counter()
        subprocess.run(frame_cmd, capture_output=True)
        frame_time = (time.perf_counter() - start) * 1000
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ (10ì´ˆ ë¶„ëŸ‰ë§Œ)
        audio_cmd = [
            "ffmpeg", "-y", "-ss", "0", "-t", "10",
            "-i", str(DEMO_VIDEO),
            "-ar", "16000", "-ac", "1",
            str(temp_dir / "audio.wav"),
            "-loglevel", "error"
        ]
        
        start = time.perf_counter()
        subprocess.run(audio_cmd, capture_output=True)
        audio_time = (time.perf_counter() - start) * 1000
        
        # ì •ë¦¬
        for f in temp_dir.glob("*"):
            f.unlink()
        temp_dir.rmdir()
        
        result = {
            "sample_duration_sec": 10,
            "frame_extraction_ms": round(frame_time, 2),
            "audio_extraction_ms": round(audio_time, 2),
            "total_extraction_ms": round(frame_time + audio_time, 2)
        }
        
        print(f"   âœ… 10ì´ˆ ì¶”ì¶œ: {result['total_extraction_ms']}ms")
        return result
    
    def benchmark_analysis_pipeline(self) -> dict:
        """ë¶„ì„ íŒŒì´í”„ë¼ì¸ ë²¤ì¹˜ë§ˆí¬ (ì´ì „ ê²°ê³¼ ê¸°ë°˜)"""
        print("\nğŸ“Š [6/6] ë¶„ì„ íŒŒì´í”„ë¼ì¸ ë²¤ì¹˜ë§ˆí¬...")
        
        # ì´ì „ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        prev_result = Path(r"D:\Ginue_AI\output\demo_analysis_v2\enhanced_result.json")
        
        if prev_result.exists():
            with open(prev_result, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            video_duration = data.get('video_info', {}).get('duration', 895)
            frame_count = data.get('frame_count', 448)
            
            # ë¶„ì„ ì‹œê°„ ì¶”ì • (ì´ì „ ì‹¤í–‰ ê¸°ì¤€)
            analysis_time_estimate = 45000  # ~45ì´ˆ (í”„ë ˆì„ ì¶”ì¶œ + ì˜¤ë””ì˜¤ ì¶”ì¶œ + ë¶„ì„)
            
            result = {
                "video_duration_sec": round(video_duration, 1),
                "frames_analyzed": frame_count,
                "estimated_analysis_time_sec": round(analysis_time_estimate / 1000, 1),
                "processing_ratio": round(video_duration / (analysis_time_estimate / 1000), 2),
                "frames_per_second": round(frame_count / (analysis_time_estimate / 1000), 2)
            }
            
            print(f"   âœ… ì²˜ë¦¬ ë¹„ìœ¨: {result['processing_ratio']}x ì‹¤ì‹œê°„")
            return result
        else:
            print("   âš ï¸ ì´ì „ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
            return {"error": "No previous analysis result"}
    
    def run_all_benchmarks(self):
        """ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸš€ GAIM Lab v3.0 Performance Benchmarking")
        print("=" * 60)
        
        self.results["benchmarks"]["api_health"] = self.benchmark_api_health()
        self.results["benchmarks"]["api_docs"] = self.benchmark_api_docs()
        self.results["benchmarks"]["frontend"] = self.benchmark_frontend()
        self.results["benchmarks"]["concurrent"] = self.benchmark_concurrent_requests()
        self.results["benchmarks"]["ffmpeg"] = self.benchmark_ffmpeg_extraction()
        self.results["benchmarks"]["analysis"] = self.benchmark_analysis_pipeline()
        
        # ê²°ê³¼ ì €ì¥
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        output_file = OUTPUT_DIR / f"benchmark_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report_path = self.generate_report()
        
        return output_file, report_path
    
    def generate_report(self) -> Path:
        """HTML ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ìƒì„±"""
        b = self.results["benchmarks"]
        
        html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>GAIM Lab v3.0 Performance Report</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: white;
            min-height: 100vh;
            padding: 40px 20px;
        }}
        .container {{ max-width: 1200px; margin: 0 auto; }}
        h1 {{
            text-align: center;
            font-size: 2.5rem;
            margin-bottom: 10px;
            background: linear-gradient(135deg, #00d4ff, #00ff88);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }}
        .subtitle {{ text-align: center; color: rgba(255,255,255,0.6); margin-bottom: 40px; }}
        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 20px;
            margin-bottom: 40px;
        }}
        .stat-card {{
            background: rgba(255,255,255,0.05);
            border-radius: 16px;
            padding: 24px;
            text-align: center;
            border: 1px solid rgba(255,255,255,0.1);
        }}
        .stat-value {{
            font-size: 2.5rem;
            font-weight: 700;
            background: linear-gradient(135deg, #00d4ff, #00ff88);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }}
        .stat-label {{ color: rgba(255,255,255,0.6); margin-top: 8px; }}
        .section {{ margin-bottom: 40px; }}
        .section-title {{ font-size: 1.5rem; margin-bottom: 20px; color: #00d4ff; }}
        .benchmark-grid {{
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 20px;
        }}
        .benchmark-card {{
            background: rgba(255,255,255,0.05);
            border-radius: 16px;
            padding: 24px;
            border: 1px solid rgba(255,255,255,0.1);
        }}
        .benchmark-card h3 {{ color: #00ff88; margin-bottom: 16px; }}
        table {{ width: 100%; border-collapse: collapse; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid rgba(255,255,255,0.1); }}
        th {{ color: rgba(255,255,255,0.6); font-weight: 500; }}
        .good {{ color: #00ff88; }}
        .warning {{ color: #ffaa00; }}
        .bad {{ color: #ff4444; }}
        .footer {{ text-align: center; margin-top: 40px; color: rgba(255,255,255,0.4); }}
    </style>
</head>
<body>
    <div class="container">
        <h1>âš¡ Performance Benchmark Report</h1>
        <p class="subtitle">GAIM Lab v3.0 | {self.results['timestamp'][:10]}</p>
        
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-value">{b.get('api_health', {}).get('avg_response_ms', 0):.0f}</div>
                <div class="stat-label">API ì‘ë‹µ (ms)</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{b.get('concurrent', {}).get('throughput_rps', 0):.1f}</div>
                <div class="stat-label">ì²˜ë¦¬ëŸ‰ (req/s)</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{b.get('frontend', {}).get('avg_page_load_ms', 0):.0f}</div>
                <div class="stat-label">í˜ì´ì§€ ë¡œë”© (ms)</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{b.get('analysis', {}).get('processing_ratio', 0):.1f}x</div>
                <div class="stat-label">ë¶„ì„ ì†ë„</div>
            </div>
        </div>
        
        <div class="section">
            <h2 class="section-title">ğŸ“Š ìƒì„¸ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼</h2>
            <div class="benchmark-grid">
                <div class="benchmark-card">
                    <h3>ğŸ”Œ API Health Check</h3>
                    <table>
                        <tr><th>í•­ëª©</th><th>ê²°ê³¼</th></tr>
                        <tr><td>í‰ê·  ì‘ë‹µì‹œê°„</td><td class="good">{b.get('api_health', {}).get('avg_response_ms', 0)}ms</td></tr>
                        <tr><td>ìµœì†Œ ì‘ë‹µì‹œê°„</td><td>{b.get('api_health', {}).get('min_response_ms', 0)}ms</td></tr>
                        <tr><td>ìµœëŒ€ ì‘ë‹µì‹œê°„</td><td>{b.get('api_health', {}).get('max_response_ms', 0)}ms</td></tr>
                        <tr><td>ì„±ê³µë¥ </td><td class="good">{b.get('api_health', {}).get('success_rate', '0%')}</td></tr>
                    </table>
                </div>
                <div class="benchmark-card">
                    <h3>ğŸ”„ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬</h3>
                    <table>
                        <tr><th>í•­ëª©</th><th>ê²°ê³¼</th></tr>
                        <tr><td>ë™ì‹œ ìš”ì²­ ìˆ˜</td><td>{b.get('concurrent', {}).get('concurrent_requests', 0)}ê°œ</td></tr>
                        <tr><td>ì„±ê³µ ìˆ˜</td><td class="good">{b.get('concurrent', {}).get('success_count', 0)}ê°œ</td></tr>
                        <tr><td>ì´ ì²˜ë¦¬ì‹œê°„</td><td>{b.get('concurrent', {}).get('total_time_ms', 0)}ms</td></tr>
                        <tr><td>ì²˜ë¦¬ëŸ‰</td><td class="good">{b.get('concurrent', {}).get('throughput_rps', 0)} req/s</td></tr>
                    </table>
                </div>
                <div class="benchmark-card">
                    <h3>ğŸ–¥ï¸ í”„ë¡ íŠ¸ì—”ë“œ í˜ì´ì§€</h3>
                    <table>
                        <tr><th>í˜ì´ì§€</th><th>ë¡œë”©ì‹œê°„</th></tr>
"""
        
        frontend_pages = b.get('frontend', {}).get('pages', {})
        for page, data in frontend_pages.items():
            time_class = "good" if data['avg_ms'] < 100 else "warning" if data['avg_ms'] < 300 else "bad"
            html += f"<tr><td>{page}</td><td class='{time_class}'>{data['avg_ms']}ms</td></tr>\n"
        
        html += f"""
                    </table>
                </div>
                <div class="benchmark-card">
                    <h3>ğŸ¬ FFmpeg ì¶”ì¶œ</h3>
                    <table>
                        <tr><th>í•­ëª©</th><th>ê²°ê³¼</th></tr>
                        <tr><td>ìƒ˜í”Œ ê¸¸ì´</td><td>{b.get('ffmpeg', {}).get('sample_duration_sec', 0)}ì´ˆ</td></tr>
                        <tr><td>í”„ë ˆì„ ì¶”ì¶œ</td><td class="good">{b.get('ffmpeg', {}).get('frame_extraction_ms', 0)}ms</td></tr>
                        <tr><td>ì˜¤ë””ì˜¤ ì¶”ì¶œ</td><td class="good">{b.get('ffmpeg', {}).get('audio_extraction_ms', 0)}ms</td></tr>
                        <tr><td>ì´ ì¶”ì¶œì‹œê°„</td><td>{b.get('ffmpeg', {}).get('total_extraction_ms', 0)}ms</td></tr>
                    </table>
                </div>
            </div>
        </div>
        
        <div class="section">
            <h2 class="section-title">ğŸ“ˆ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥</h2>
            <div class="benchmark-card">
                <table>
                    <tr><th>í•­ëª©</th><th>ê²°ê³¼</th><th>í‰ê°€</th></tr>
                    <tr>
                        <td>ì˜ìƒ ê¸¸ì´</td>
                        <td>{b.get('analysis', {}).get('video_duration_sec', 0)}ì´ˆ</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>ë¶„ì„ í”„ë ˆì„ ìˆ˜</td>
                        <td>{b.get('analysis', {}).get('frames_analyzed', 0)}ê°œ</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>ì˜ˆìƒ ë¶„ì„ ì‹œê°„</td>
                        <td>{b.get('analysis', {}).get('estimated_analysis_time_sec', 0)}ì´ˆ</td>
                        <td class="good">âœ… ë¹ ë¦„</td>
                    </tr>
                    <tr>
                        <td>ì²˜ë¦¬ ë¹„ìœ¨</td>
                        <td><strong>{b.get('analysis', {}).get('processing_ratio', 0)}x ì‹¤ì‹œê°„</strong></td>
                        <td class="good">âœ… ìš°ìˆ˜</td>
                    </tr>
                    <tr>
                        <td>í”„ë ˆì„ ì²˜ë¦¬ ì†ë„</td>
                        <td>{b.get('analysis', {}).get('frames_per_second', 0)} fps</td>
                        <td class="good">âœ… ì–‘í˜¸</td>
                    </tr>
                </table>
            </div>
        </div>
        
        <div class="section">
            <h2 class="section-title">ğŸ“‹ ì„±ëŠ¥ ìš”ì•½</h2>
            <div class="benchmark-card">
                <ul style="list-style: none; line-height: 2;">
                    <li>âœ… API ì‘ë‹µì‹œê°„: <strong class="good">{b.get('api_health', {}).get('avg_response_ms', 0):.0f}ms</strong> (ëª©í‘œ: &lt;100ms)</li>
                    <li>âœ… ë™ì‹œ ì²˜ë¦¬ëŸ‰: <strong class="good">{b.get('concurrent', {}).get('throughput_rps', 0):.1f} req/s</strong></li>
                    <li>âœ… í”„ë¡ íŠ¸ì—”ë“œ ë¡œë”©: <strong class="good">{b.get('frontend', {}).get('avg_page_load_ms', 0):.0f}ms</strong></li>
                    <li>âœ… ë¶„ì„ ì†ë„: <strong class="good">{b.get('analysis', {}).get('processing_ratio', 0):.1f}x ì‹¤ì‹œê°„</strong> (15ë¶„ ì˜ìƒ â†’ 45ì´ˆ ë¶„ì„)</li>
                </ul>
            </div>
        </div>
        
        <div class="footer">
            <p>Â© 2026 ê²½ì¸êµìœ¡ëŒ€í•™êµ GAIM Lab v3.0</p>
            <p>Performance Benchmark Report</p>
        </div>
    </div>
</body>
</html>
"""
        
        report_path = OUTPUT_DIR / f"benchmark_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html)
        
        return report_path


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    benchmark = PerformanceBenchmark()
    output_file, report_path = benchmark.run_all_benchmarks()
    
    print("\n" + "=" * 60)
    print("âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    print("=" * 60)
    
    b = benchmark.results["benchmarks"]
    print(f"\nğŸ“Š ì£¼ìš” ê²°ê³¼:")
    print(f"   â€¢ API ì‘ë‹µ: {b.get('api_health', {}).get('avg_response_ms', 0):.1f}ms")
    print(f"   â€¢ ë™ì‹œ ì²˜ë¦¬ëŸ‰: {b.get('concurrent', {}).get('throughput_rps', 0):.1f} req/s")
    print(f"   â€¢ í˜ì´ì§€ ë¡œë”©: {b.get('frontend', {}).get('avg_page_load_ms', 0):.1f}ms")
    print(f"   â€¢ ë¶„ì„ ì†ë„: {b.get('analysis', {}).get('processing_ratio', 0):.1f}x ì‹¤ì‹œê°„")
    
    print(f"\nğŸ“ ê²°ê³¼ íŒŒì¼:")
    print(f"   â€¢ {output_file}")
    print(f"   â€¢ {report_path}")
    
    return str(report_path)


if __name__ == "__main__":
    report = main()
    print(f"\nğŸŒ ë¦¬í¬íŠ¸ ì—´ê¸°: {report}")
